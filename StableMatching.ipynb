{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "rrAST75vMCSw",
        "outputId": "7e3dc50f-bd57-437f-f27c-c019e82667cb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/root/Downloads/Ridesharing_S_1.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4121327232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load the CSV file into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdriverdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Announcement'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/Downloads/Ridesharing_S_1.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "# Define the path to your Downloads folder\n",
        "downloads_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
        "\n",
        "# Replace 'your_file.csv' with the name of your CSV file\n",
        "file_name = 'Ridesharing_S_1.csv'\n",
        "file_path = os.path.join(downloads_path, file_name)\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "driverdf = df[df['Announcement'] < 100000]\n",
        "riderdf = df[df['Announcement'] > 100000]\n",
        "riderdf.head()\n",
        "\n",
        "driverdf = driverdf.sort_values(by='Announcementtime')\n",
        "riderdf = riderdf.sort_values(by='Announcementtime')\n",
        "driverdf=driverdf.head(500)\n",
        "riderdf=riderdf.head(500)\n",
        "\n",
        "driverdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making new columns for variables as given in the research paper\n",
        "driverdf=driverdf.rename(columns={'Announcementtime':'t','Earliesttime':'e','Latesttime':'l'})\n",
        "driverdf['q']=driverdf['l']-driverdf['Time_Car-Peak']\n",
        "\n",
        "riderdf=riderdf.rename(columns={'Announcementtime':'t','Earliesttime':'e','Latesttime':'l'})\n",
        "riderdf['q']=riderdf['l']-riderdf['Time_Car-Peak']\n",
        "\n",
        "# create a list of pairing between every announcement\n",
        "\n",
        "# Add a key column to perform Cartesian product\n",
        "driverdf['key'] = 1\n",
        "riderdf['key'] = 1\n",
        "\n",
        "# Perform the Cartesian product\n",
        "pairdf = pd.merge(driverdf, riderdf, on='key').drop('key', axis=1)\n",
        "\n",
        "pairdf['Combined_Announcement'] = pairdf['Announcement_x'].astype(str) + pairdf['Announcement_y'].astype(str)\n",
        "pairdf = pairdf.drop(columns=['Announcement_x', 'Announcement_y'])\n",
        "\n",
        "# Get the column names\n",
        "columns = pairdf.columns.tolist()\n",
        "\n",
        "# Move the last column to the first position\n",
        "new_order = [columns[-1]] + columns[:-1]\n",
        "\n",
        "# Reorder the DataFrame\n",
        "pairdf = pairdf[new_order]\n",
        "\n",
        "pairdf.shape\n",
        "#final"
      ],
      "metadata": {
        "id": "ICltpxW4MERK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pairing preprocessing, removing infeasible pairings.\n",
        "indices_to_drop = []\n",
        "for index_row in pairdf.iterrows():\n",
        "    driverorigin=(row['Origin_Latitude_x'],row['Origin_Longitude_x'])\n",
        "    driverendpoint=(row['Destination_Latitude_x'],row['Destination_Longitude_x'])\n",
        "    riderorigin=(row['Origin_Latitude_y'],row['Origin_Longitude_y'])\n",
        "    riderendpoint=(row['Destination_Latitude_y'],row['Destination_Longitude_y'])\n",
        "    driverdistance=row['Distance_Car-Peak_x']\n",
        "    drivertime=row['Time_Car-Peak_x']\n",
        "    ridertime=row['Time_Car-Peak_y']\n",
        "    l_x=row['l_x']\n",
        "    l_y=row['l_y']\n",
        "    e_x=row['e_x']\n",
        "    e_y=row['e_y']\n",
        "\n",
        "k=min(l_y-ridertime-((geodesic(driverorigin, riderorigin).kilometers)*driverdistance/drivertime),l_x-ridertime-((geodesic(riderorigin, driverorigin).kilometers)*driverdistance/drivertime))\n",
        "if((k-e_x)<0) and ((k+((geodesic(driverorigin, riderorigin).kilometers)*driverdistance/drivertime)-e_y)<0):\n",
        "    indices_to_drop.append(index)\n",
        "\n",
        "processdf=pairdf.drop(indices_to_drop)\n",
        "\n",
        "processdf.shape"
      ],
      "metadata": {
        "id": "blqWVi8UMJfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding weightage column for net distance savings.\n",
        "processdf['weight']=0\n",
        "for index,row in processdf.iterrows():\n",
        "    driverorigin=(row['Origin_Latitude_x'],row['Origin_Longitude_x'])\n",
        "    driverendpoint=(row['Destination_Latitude_x'],row['Destination_Longitude_x'])\n",
        "    riderorigin=(row['Origin_Latitude_y'],row['Origin_Longitude_y'])\n",
        "    riderendpoint=(row['Destination_Latitude_y'],row['Destination_Longitude_y'])\n",
        "    drivertriplelength=row['Distance_Car-Peak_x']\n",
        "    drivertime=row['Time_Car-Peak_x']\n",
        "    ridertriplelength=row['Distance_Car-Peak_y']\n",
        "    ridertime=row['Time_Car-Peak_y']\n",
        "    nomatchlength=drivertriplelength+ridertriplelength\n",
        "    withmatchlength=geodesic(driverorigin, riderorigin).kilometers+geodesic(riderorigin, riderendpoint).kilometers+geodesic(riderendpoint, driverendpoint).kilometers\n",
        "    processdf.at[index, 'weight'] = nomatchlength-withmatchlength  # Example operation\n",
        "\n",
        "weights=processdf['weight'].tolist()\n",
        "\n",
        "#adding weightage column for distance proximity index\n",
        "processdf['weight']=0\n",
        "for index,row in processdf.iterrows():\n",
        "    drivertriplelength=row['Distance_Car-Peak_x']\n",
        "    ridertriplelength=row['Distance_Car-Peak_y']\n",
        "    processdf.at[index, 'weight'] = min(drivertriplelength/ridertriplelength,ridertriplelength/drivertriplelength)  # Example operation\n",
        "\n",
        "weights=processdf['weight'].tolist()\n",
        "\n",
        "#adding weightage column for adjusted distance proximity index\n",
        "processdf['weight']=0\n",
        "for index,row in processdf.iterrows():\n",
        "    driverorigin=(row['Origin_Latitude_x'],row['Origin_Longitude_x'])\n",
        "    driverendpoint=(row['Destination_Latitude_x'],row['Destination_Longitude_x'])\n",
        "    riderorigin=(row['Origin_Latitude_y'],row['Origin_Longitude_y'])\n",
        "    riderendpoint=(row['Destination_Latitude_y'],row['Destination_Longitude_y'])\n",
        "    drivertriplelength=row['Distance_Car-Peak_x']\n",
        "    drivertime=row['Time_Car-Peak_x']\n",
        "    ridertriplelength=row['Distance_Car-Peak_y']\n",
        "    ridertime=row['Time_Car-Peak_y']\n",
        "    withmatchlength=geodesic(driverorigin, riderorigin).kilometers+geodesic(riderorigin, riderendpoint).kilometers+geodesic(riderendpoint, driverendpoint).kilometers\n",
        "    processdf.at[index, 'weight'] = (drivertriplelength/withmatchlength)*min(drivertriplelength/ridertriplelength,ridertriplelength/drivertriplelength)"
      ],
      "metadata": {
        "id": "6IsbnLrXMLRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normal model no weights\n",
        "from gurobipy import Model, GRB\n",
        "\n",
        "drivers=processdf['Announcement_x'].unique()\n",
        "riders=processdf['Announcement_y'].unique()\n",
        "possible_matches=set(zip(processdf['Announcement_x'],processdf['Announcement_y']))\n",
        "\n",
        "model=Model('maximizer')\n",
        "x=model.addVars(possible_matches,vtype=GRB.BINARY, name=\"x\")\n",
        "model.setObjective(x.sum(),GRB.MAXIMIZE)\n",
        "\n",
        "for d in drivers:\n",
        "    model.addConstr(sum(x[d,r] for r in riders if (d,r) in x)<=1)\n",
        "\n",
        "for r in riders:\n",
        "    model.addConstr(sum(x[d,r] for d in drivers if (d,r) in x)<=1)\n",
        "model.optimize()"
      ],
      "metadata": {
        "id": "P1613hQzMM-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model with weightage\n",
        "from gurobipy import Model, GRB\n",
        "\n",
        "drivers=processdf['Announcement_x'].unique()\n",
        "riders=processdf['Announcement_y'].unique()\n",
        "possible_matches=set(zip(processdf['Announcement_x'],processdf['Announcement_y'],processdf['weight']))\n",
        "\n",
        "model=Model('maximizer')\n",
        "x=model.addVars([(d,r,weight) for d,r,weight in possible_matches],vtype=GRB.BINARY, name=\"x\")\n",
        "model.setObjective(sum(x[d,r,weight]*weight for d,r,weight in possible_matches),GRB.MAXIMIZE)\n",
        "\n",
        "for d in drivers:\n",
        "    model.addConstr(sum(x[d,r,weight] for driver_match,r,weight in possible_matches if driver_match==d)<1)\n",
        "\n",
        "for r in riders:\n",
        "    model.addConstr(sum(x[d,r,weight] for d,rider_match,weight in possible_matches if rider_match==r)<1)\n",
        "model.optimize()"
      ],
      "metadata": {
        "id": "5IDGxnYZMPMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#performance evaluation terminal\n",
        "\n",
        "#matchrate calc\n",
        "matched2=0\n",
        "for dr2 in possible_matches:\n",
        "    if x[dr2].x>0.5:\n",
        "        matched2=matched2+1\n",
        "matchrate=matched2*2/(len(drivers)+len(riders))\n",
        "print(matchrate)\n",
        "\n",
        "#Average Kilometer Saved (AKS) calc\n",
        "ktotal=0\n",
        "matched3=0\n",
        "for dr in possible_matches:\n",
        "    if x[dr].x>0.5:\n",
        "        drivertrip = driverdf[driverdf['Announcement'] == dr[0]]['Distance_Car-Peak']\n",
        "        drivertriplength=float(drivertrip)\n",
        "        ridertrip = riderdf[riderdf['Announcement'] == dr[1]]['Distance_Car-Peak']\n",
        "        ridertriplength=float(ridertrip)\n",
        "        nomatchlength=drivertriplength+ridertriplength\n",
        "\n",
        "        driverrorw=driverdf[driverdf['Announcement'] == dr[0]]\n",
        "        drivrorigin=(float(driverrorw['Origin_Latitude']),float(driverrorw['Origin_Longitude']))\n",
        "        driverendpoint=(float(driverrorw['Destination_Latitude']),float(driverrorw['Destination_Longitude']))\n",
        "\n",
        "        riderrerow=riderdf[riderdf['Announcement'] == dr[1]]\n",
        "        riderorigin=(float(riderrerow['Origin_Latitude']),float(riderrerow['Origin_Longitude']))\n",
        "        riderendpoint=(float(riderrerow['Destination_Latitude']),float(riderrerow['Destination_Longitude']))\n",
        "\n",
        "        withmatchlength=geodesic(drivrorigin, riderorigin).kilometers+geodesic(riderorigin, riderendpoint).kilometers+geodesic(riderendpoint, driverendpoint).kilometers\n",
        "        matched3=matched3+1\n",
        "        ktotal=ktotal+nomatchlength-withmatchlength\n",
        "aks=ktotal/matched3\n",
        "print(aks)"
      ],
      "metadata": {
        "id": "hVVQNUdNMQ4m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}